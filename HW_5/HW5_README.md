# ДЗ № 5
**Цель работы**:
- [x] Выполнение шагов, продемонстрированных на вебинаре, с использованием PySpark для обучения
модели обнаружения мошенничества (fraud detection) 
- [x] Поднять MLFlow. 
- [x] Сохранить все артефакты с моделью в MLFlow, обязательно наличие Object Storage
- [x] Настроить переобучение по расписанию при помощи Airflow на новых данных
- [ ] Проверить качество и эффективность модели обнаружения мошенничества - здесь я задание не выполнила до конца, так как работала с данными за 1 день в целях экономии времени и ресурсов. Также использовала уже готовую метрику areaUnderROC, а не рассчитывала изначально запланированную F1 орять же для экономии времени. В следующем задании попробую взять данные за несколько дней.
<hr>

# Создание модели для обучения выявления мошеннических транзакций
В качестве основной модели я буду использовать Logistic Regression. Она будет обучаться на обработанных данных из предыдущего шага. В качестве учебного примера и экономии ресурсов буду обучать модель на данных за 1 день. В следующем задании попробую обучать за несколько дней. Метрики за каждый цикл обучения будут прогружаться в MLFlow. Процесс обучения включает:

- разбивку на train/test
- создание вектора признаков и его нормализация
- подбор гиперпараметров
- логирование метрик и лучшей модели в MLFlow.
  
Скрипт для обучения модели можно посмотреть [здесь](https://github.com/shakhovak/MLOps_HW/blob/master/HW_5/model_train_fin.py).

# MLFlow
Поднимать MLFlow я буду на отдельной ВМ. Буду оринетироваться на [инструкцию](https://cloud.yandex.ru/ru/docs/datasphere/tutorials/mlflow-datasphere#setup-mlflow) от Yandex. Основные шаги:
1. Создать ВМ с Ubuntu
2. Установить на ней необходимые библиотеки

```python 
conda install -c conda-forge mlflow
conda install -c anaconda boto3
pip install psycopg2-binary
pip install pandas
```
3. Добавить доступы к S3
4. Создать базу данных с помощью сервиса Managed Service for PostgreSQL

![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/0670c858-c15b-4596-a2f0-322b16215655)

6. Запустить MLFlow Tracking Server 

# Обучение модели
Для обучения модели я создала кластер для вычислений как в предыдущем задании.

![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/57cd210a-1003-4d23-b304-ba11e8a116b9)

При инициализации кластера нужно указать, какие дополнительные пакеты нужно установить для работы со скриптами. Пакеты указываются в свойствах/properties.

```python
pip:mlflow : 2.3.2
pip:urllib3 : 1.26.16
```

# Airflow

Как в предыдущем задании, я подготовила DAG для автоматического выполнения задачи предобработки данных и обучения модели, я создала ВМ c Airflow. Посмотреть DAG можно [здесь](https://github.com/shakhovak/MLOps_HW/blob/master/HW_5/data_proc2.py)

> [!IMPORTANT]
> **Я немного поменяла DAG: убрала из него создание и удаление кластера, так как нужно заполнять properties, а этот пункт добавлен в коннектор только с 3 версии Airflow. На ВМ устанавливается автоматически только 2.**
>

![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/a866d782-0dd5-4841-9d0e-f07f5b0f47bb)

 
# Результаты обучения и выводы:
Результаты обучения отражаются в базе данных и в IU MLFlow и приведены на прин-скринах ниже. 

Успешно отработал Airflow:
![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/f337ce63-823d-4d40-b64d-cda0858e55e2)

UI ML Flow:
![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/61414787-c874-4199-b37f-c419b9680f75)

S3 c артефактом модели:
![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/8e14723d-048b-4b73-9c0b-ce26119bd3d5)

Также сохранилась информация и в базе данных:
![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/6d3f3e66-2bc2-46b7-8583-c4a6194f5c46)

После обучения я удалила все ВМ и базы данных.



   
