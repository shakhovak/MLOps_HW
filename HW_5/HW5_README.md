# ДЗ № 5
**Цель работы**:
1. Выполнение шагов, продемонстрированных на вебинаре, с использованием PySpark для обучения
модели обнаружения мошенничества (fraud detection);
2. Поднять MLFlow (варианты поднятия на усмотрение студента, рекомендуется использовать сценарий
номер 4. 
3. Сохранить все артефакты с моделью в MLFlow, обязательно наличие Object Storage;
4. Настроить переобучение по расписанию при помощи Airflow на новых данных;
5. Проверить качество и эффективность модели обнаружения мошенничества
<hr>

# Создание модели для обучения выявления мошеннических транзакций
В качестве основной модели я буду использовать Logistic Regression. Она будет обучаться на обработанных данных из предыдущего шага. В качестве учебного примера и экономии ресурсов буду обучать модель на данных за 1 день, 2 дня и 3 дня. Метрики за каждый цикл обучения будут прогружаться в MLFlow. Также в процесс я включила несколько гиперпараметров для подбора. 
Скрипт для обучения модели можно посмотреть здесь.

# MLFlow
Поднимать MLFlow я буду на отдельной ВМ. Буду оринетироваться на [инструкцию](https://cloud.yandex.ru/ru/docs/datasphere/tutorials/mlflow-datasphere#setup-mlflow) от Yandex. Основные шаги:
1. Создать ВМ с Ubuntu
2. Установить на ней необходимые библиотеки

```python 
conda install -c conda-forge mlflow
conda install -c anaconda boto3
pip install psycopg2-binary
pip install pandas
```
3. Добавить доступы к S3
4. Созадать базу данных с помощью сервиса Managed Service for PostgreSQL

![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/31ef11dd-9f08-48c6-9a19-faa0d0a22932)

6. Запустить MLFlow Tracking Server 

# Обучение модели
Для обучения модели я создала кластер для вычислений как в предыдщем задании.
   ![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/71d00252-a0b2-4c5f-8005-0188f01f6819)
   
 > [!IMPORTANT]
> **Мне не удалось запустить задание на кластере, так как не устанавливался MLFlow в рамках автоматического запуска задания. В результате я скопировала скрипт на кластер через терминал и запускала его вручную в CLI через spark-submit!**
> DAGs в Airflow у меня основаны на создании кластера и запуска на нем задания с последующим удалением кластера. Так как мне не удалось подключить библиоетку MLFlow для выполнения задания, то я решила пропустить этот шаг и сделала запрос в поддержку.

# Результаты обучения
Результаты обучения отражаются в базе данных и в IU MLFlow



   
