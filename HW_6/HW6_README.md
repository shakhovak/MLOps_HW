# ДЗ № 5
**Цель работы**:
- [x] Выберите стратегию для валидации модели.
- [x] Оцените метрики модели на выбранной стратегии.
- [x] Подготовьте новую модель и проведите A/B тестирование на валидации.
- [x] Добавьте в AirFlow шаг по валидации модели и построению отчета.
<hr>

## Описание подхода к решению задачи
Настроим инфраструктуру как в предыдущей задаче:
1. ВМ с настроенным на ней MLFlow, кластер с базой PostgresSQL для хранения метрик MLFLOW и s3 бакет для артефактов.
2. ВМ с установленным на ней Airflow
3. HDFS кластер для проведения расчетов

![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/8cdd7d27-bf05-452c-b2ba-3e22d783c14d)

В Airflow добавила DAG (можно посмотреть [здесь](https://github.com/shakhovak/MLOps_HW/blob/master/HW_6/data_proc2.py) , который на созданном кластере создает и запускает два задания:
1. Предобработка текстовых данных, как в предыдущих заданиях
2. Обучение и оценка модели
   
![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/16eb78cc-9f68-4bb3-ac65-9dd8aa5ca7d6)

## Стратегия валидации модели
Для учебного примера я оставила метрику areaUnderROC, так как она уже встроена в pyspark и быстрее всего вычисляется. В качестве основной модели я взяла Logistic Regression для бинарной классификации. Для А/В тестирования буду использовать гипотезу: 
- **нулевая гипотеза"**:areaUnderROC по обучению модели Logistic Regression из коробки НЕ будет статистически отличаться от той же метрки для той же модели, но с подобранными гиперпараметрами
-  **основная гипотеза"**:areaUnderROC по обучению модели Logistic Regression из коробки будет статистически отличаться от той же метрки для той же модели, но с подобранными гиперпараметрами

Для проверки гипотезы:
- я обучу модель Logistic Regression без подбора гипрепараметров и сделаю на тестовых данных рандомную выборку в размере 100 экземпляров выбранной метрики, сохраню распределение метрики в s3 в качестве артефакта
- оценю получившиеся распределение метрик на нормальность распределения с помощью теста Шапиро-Уилка и занесу эту метрику в ML Flow
- подберу гиперпараметры модели и сделаю на новой моделе такую же рандомную выборку метрики. Также сохраню получившиеся распрделение в качестве артефакта и оценю с помощью теста Шапиро-Уилка на нормальность
- для оценки гипотез воспользуюсь тестом Стьюдента для сравнения 2-х нормальных распределений. Если полученной p-value будет ниже альфа=0.01, то отвергаем нулевую гипотезу и говорим о том, что распределения разные. Соответвенно сохраняем в качестве основно модель с подобранными гипрепараметрами. Если же p-value будеи больше альфа, то принимаем нулевую гипотезу и сохраняем в качестве основной модель из коробки.

  Детально код по обучению и оценки модели можно посмотреть [здесь](https://github.com/shakhovak/MLOps_HW/blob/master/HW_6/model_train_valid.py)

## Результаты работы

  
