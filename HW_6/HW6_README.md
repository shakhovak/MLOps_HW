# ДЗ № 5
**Цель работы**:
- [x] Выберите стратегию для валидации модели.
- [x] Оцените метрики модели на выбранной стратегии.
- [x] Подготовьте новую модель и проведите A/B тестирование на валидации.
- [x] Добавьте в AirFlow шаг по валидации модели и построению отчета.
<hr>

## Описание подхода к решению задачи
Настроим инфраструктуру как в предыдущей задаче:
1. ВМ с настроенным на ней MLFlow, кластер с базой PostgresSQL для хранения метрик MLFLOW и s3 бакет для артефактов.
2. ВМ с установленным на ней Airflow
3. HDFS кластер для проведения расчетов, на кластере при инициализации устанавливается MLFlow через свойства (описано в предыдущем задании)

![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/8cdd7d27-bf05-452c-b2ba-3e22d783c14d)

В Airflow я добавила DAG (можно посмотреть [здесь](https://github.com/shakhovak/MLOps_HW/blob/master/HW_6/data_proc2.py) , который на созданном кластере создает и запускает два задания:
1. Предобработка текстовых данных, как в предыдущих заданиях
2. Обучение и оценка модели
   
![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/16eb78cc-9f68-4bb3-ac65-9dd8aa5ca7d6)

## Стратегия валидации модели
Для учебного примера я оставила метрику areaUnderROC, так как она уже встроена в pyspark и быстрее всего вычисляется. В качестве основной модели я взяла Logistic Regression для бинарной классификации. Для А/В тестирования буду использовать гипотезы: 
- **нулевая гипотеза"**:areaUnderROC по обучению модели Logistic Regression из коробки НЕ будет статистически отличаться от той же метрки для той же модели, но с подобранными гиперпараметрами
-  **основная гипотеза"**:areaUnderROC по обучению модели Logistic Regression из коробки будет статистически отличаться от той же метрки для той же модели, но с подобранными гиперпараметрами

Для проверки гипотезы:
- :pencil: я обучу модель Logistic Regression без подбора гиперпараметров (из коробки) и сделаю на тестовых данных рандомную выборку в размере 100 экземпляров выбранной метрики, сохраню распределение метрики в s3 в качестве артефакта (понятно, что я не проверяла размер выборки статистически, а взяла размер как из примера на лекции; по правилам, нудно былобы использовать специальный калькулятор с учтом уровня дисперсии в основной совокупности. Я решила пойти по более простому пути в учебных целях. Кроме того, при семплировании выборки я брала только 1% от всех полученных предсказаний для формирования распределения метрики).
- :pencil: оценю получившееся распределение метрик на нормальность распределения с помощью теста Шапиро-Уилка и занесу эту метрику в ML Flow
- :pencil: подберу гиперпараметры модели и сделаю на новой моделе такую же рандомную выборку метрики как на первоначальной. Также сохраню получившиеся распределение в качестве артефакта и оценю с помощью теста Шапиро-Уилка на нормальность.
- :pencil: для оценки гипотез воспользуюсь тестом Стьюдента для сравнения 2-х нормальных распределений. Если полученная p-value будет ниже альфа=0.01, то отвергаем нулевую гипотезу и говорим о том, что распределения разные. Соответственно сохраняем в качестве основно модель с подобранными гипрепараметрами. Если же p-value будет больше альфа, то принимаем нулевую гипотезу и сохраняем в качестве основной модель из коробки.

  Детально код по обучению и оценки модели можно посмотреть [здесь](https://github.com/shakhovak/MLOps_HW/blob/master/HW_6/model_train_valid.py)

## Результаты работы
Итак, Airflow отработал несколько запусков (интервал между запусками стоит в 70 минут). Для 1-го запуска я использорвала файл за один день, потом имитировала приход данных еще за один день и повторно модель уже обучается на данных за 2 дня. Третий запуск я отключу после оформления отчета.

![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/4620a8a2-40ff-4f3e-8a23-1597b9d52d7d)

Модели, метрики и параметры сохранились в базу данных и в бакет s3:

![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/8d7d480a-819a-406b-b95b-09e0bc2de235)

![image](https://github.com/shakhovak/MLOps_HW/assets/89096305/fb9dbee3-0333-4292-bc33-aafe93e95f08)

Как видно из записанных в ML Flow данных, оба распределения метрик - близки к нормальному распределению, так как тесты Шапиро-Уилка дают результат больше 0.05, но результаты теста Стьюдента говорят о том, что выборки статистически похожие. Поэтому в обоих случаях сохранилась обученная модель из коробки.

Неплохо бы было добавить и основную метрику areaUnderRoc, как я делала в предудущем примере. 
После написания отчета, я удалила кластер и все ВМ.






  
