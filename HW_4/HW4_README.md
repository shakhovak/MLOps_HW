# ДЗ № 4
**Цель работы**: В данном домашнем задании Вы потренируетесь в организации периодического запуска процедуры очистки данных с помощью инструмента Apache Airflow, познакомитесь с концепцией ориентированных
направленных графов (DAGs), с помощью которых организуется последовательность запуска задач по расписанию, научитесь разрабатывать собственные графы с помощью языка Python для Apache Airflow.

## Общий подход
Для решения этой задачи воспользуюсь встроенным в коробоку Airflow провайдером yandex. Этот провайдер содержит оператоторы, которые позволяют сделать следующие шага:

1. Создать временный кластер
2. Запустить на этом кластере job 
3. Удалить временный кластер

Для управления DAG я создала сервисный аккаунт, которому добавила роли, нкобходимые для выполнения описанных выше задач.
![Alt text](image.png)

Для подключения это аккаунта в Airflow созданы 2 ключа:
1. Для s3 статический ключ
2. Для всего сервисного аккаунта - авторизованный ключ, который позволит Airflow создавать и удалять кластеры + jobs

# 1. Запустить Airflow и создать подкючения
Запускасть Airflow я буду на ВМ. Так как задание я собираюсб выполнять с помощью провайдера Yandex, уже встроенного в готовый Airflow на ВМ, то в качестве подключений я буду использовать 2 основных:
1. для подключения с бакетам s3, где будут использоваться статисеские ключи, сгенерированные для сервисного аккаунта
![Alt text](image-1.png)
2. для воз
![Alt text](image-2.png)